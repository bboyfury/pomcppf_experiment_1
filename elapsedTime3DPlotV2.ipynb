{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19256\\373812787.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# Read data from CSV files\n",
    "job_info_df = pd.read_csv('https://raw.githubusercontent.com/bboyfury/pomcppf_experiment_1/main/job_info_output.csv')\n",
    "sacct_df = pd.read_csv('https://raw.githubusercontent.com/bboyfury/pomcppf_experiment_1/main/job_statistics_output.csv')\n",
    "\n",
    "# Ensure JobID columns are strings\n",
    "job_info_df['JobID'] = job_info_df['JobID'].astype(str)\n",
    "sacct_df['JobID'] = sacct_df['JobID'].astype(str)\n",
    "\n",
    "# Extract the main JobID (before any dots or underscores)\n",
    "sacct_df['MainJobID'] = sacct_df['JobID'].str.split(r'[._]').str[0]\n",
    "job_info_df['MainJobID'] = job_info_df['JobID'].str.split(r'[._]').str[0]\n",
    "\n",
    "# Merge the two dataframes on 'MainJobID'\n",
    "merged_df = pd.merge(job_info_df, sacct_df, on='MainJobID')\n",
    "\n",
    "# Function to convert MaxRSS to bytes\n",
    "def parse_maxrss(value):\n",
    "    if isinstance(value, str) and value.endswith('K'):\n",
    "        return float(value[:-1]) * 1024\n",
    "    elif isinstance(value, str) and value.endswith('M'):\n",
    "        return float(value[:-1]) * 1024 * 1024\n",
    "    elif isinstance(value, str) and value.endswith('G'):\n",
    "        return float(value[:-1]) * 1024 * 1024 * 1024\n",
    "    else:\n",
    "        return float(value)\n",
    "\n",
    "# Convert necessary columns to numeric types\n",
    "numeric_columns = ['TRAJECTORIES', 'Horizon', 'PARTICLES', 'ElapsedRaw']\n",
    "for col in numeric_columns:\n",
    "    merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "merged_df['ElapsedRaw'] = merged_df['ElapsedRaw'] / 60  # Convert seconds to minutes\n",
    "\n",
    "# Drop rows with missing values in key columns\n",
    "merged_df.dropna(subset=['TRAJECTORIES', 'Horizon', 'ElapsedRaw', 'PARTICLES'], inplace=True)\n",
    "\n",
    "# Normalize MaxRSS_MB for color mapping\n",
    "\n",
    "# Scale PARTICLES for marker size (adjust scaling factor for visual clarity)\n",
    "particle_sizes = merged_df['PARTICLES'] / merged_df['PARTICLES'].max() * 100  # Scaling particle size\n",
    "\n",
    "# Now, we create the 3D scatter plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "norm = Normalize(vmin=merged_df['ElapsedRaw'].min(), vmax=merged_df['ElapsedRaw'].max())\n",
    "\n",
    "\n",
    "sc = ax.scatter(merged_df['Horizon'], merged_df['TRAJECTORIES'], merged_df['ElapsedRaw'], \n",
    "                c=merged_df['ElapsedRaw'], cmap='RdYlGn_r', norm=norm, s=particle_sizes, marker='o')\n",
    "\n",
    "# Add a color bar for Elapsed Time (seconds)\n",
    "plt.colorbar(sc, ax=ax, label='Elapsed Time (minutes)')\n",
    "# Set labels\n",
    "ax.set_xlabel('Horizon')\n",
    "ax.set_ylabel('TRAJECTORIES')\n",
    "ax.set_zlabel('Elapsed Time (minutes)')\n",
    "\n",
    "# Add a legend for particle size\n",
    "# Creating a few dummy points with varying sizes for the legend\n",
    "for particle_count, size in zip([5, 10, 20, 30, 50, 100, 200], [5, 10, 20, 30, 50, 100, 200]):\n",
    "    ax.scatter([], [], [], s=size, c='gray', label=f'{particle_count} PARTICLES')\n",
    "\n",
    "# Add the legend for particle sizes\n",
    "ax.legend(loc='upper right', title='Particle Size', bbox_to_anchor=(1.5, 1), prop={'size': 10})\n",
    "# Customize the view angle\n",
    "ax.view_init(elev=35., azim=35)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
